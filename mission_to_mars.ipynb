{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "\n",
    "# https://splinter.readthedocs.io/en/latest/drivers/chrome.html\n",
    "# from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_p': 'NASA’s next mission to Mars, InSight, is scheduled to launch Saturday, May 5, on a first-ever mission to study the heart of the Red Planet.',\n",
       " 'news_title': 'NASA Sets Sights on May 5 Launch of InSight to Mars'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splinter \n",
    "#executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "#browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# selenium \n",
    "def scrape_news():\n",
    "    browser = webdriver.Chrome('chromedriver.exe')\n",
    "    news = {}\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    html = browser.page_source \n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # print(soup.prettify())\n",
    "    \n",
    "    \n",
    "    news[\"news_title\"] = soup.find(\"div\", class_=\"content_title\").get_text()\n",
    "    news[\"news_p\"] = soup.find(\"div\", class_=\"article_teaser_body\").get_text()\n",
    "\n",
    "    return news\n",
    "\n",
    "scrape_news()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data-fancybox-href'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-0c6629ff7a0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeaturedimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mscrape_featuredimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-113-0c6629ff7a0a>\u001b[0m in \u001b[0;36mscrape_featuredimage\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmylink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mfeaturedimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"featured_image_url\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmylink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data-fancybox-href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m#soup.find(\"a\", class_=\"button fancybox\").get_link()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data-fancybox-href'"
     ]
    }
   ],
   "source": [
    "def scrape_featuredimage():\n",
    "    browser = webdriver.Chrome('chromedriver.exe')\n",
    "    featuredimage = {}\n",
    "    url = 'https://www.jpl.nasa.gov/spaceimages'\n",
    "    url2 = 'https://www.jpl.nasa.gov'\n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    html = browser.page_source \n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # print(soup.prettify())\n",
    "    \n",
    "    mylink.attrs\n",
    "    featuredimage[\"featured_image_url\"] = url2 + mylink.attrs['data-fancybox-href']\n",
    "    #soup.find(\"a\", class_=\"button fancybox\").get_link()\n",
    "    \n",
    "    return featuredimage\n",
    "\n",
    "scrape_featuredimage()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mars_weather': 'Sol 2033 (April 25, 2018), Sunny, high -10C/14F, low -71C/-95F, pressure at 7.23 hPa, daylight 05:24-17:20'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_marsweather():\n",
    "    browser = webdriver.Chrome('chromedriver.exe')\n",
    "    marsweather = {}\n",
    "    url = 'https://twitter.com/marswxreport?lang=en'\n",
    "    \n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    html = browser.page_source \n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # print(soup.prettify())\n",
    "    \n",
    "    mylink.attrs\n",
    "    marsweather[\"mars_weather\"] = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "    #soup.find(\"a\", class_=\"button fancybox\").get_link()\n",
    "    \n",
    "    return marsweather\n",
    "\n",
    "scrape_marsweather()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                      0                              1\n",
       " 0  Equatorial Diameter:                       6,792 km\n",
       " 1       Polar Diameter:                       6,752 km\n",
       " 2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
       " 3                Moons:            2 (Phobos & Deimos)\n",
       " 4       Orbit Distance:       227,943,824 km (1.52 AU)\n",
       " 5         Orbit Period:           687 days (1.9 years)\n",
       " 6  Surface Temperature:                  -153 to 20 °C\n",
       " 7         First Record:              2nd millennium BC\n",
       " 8          Recorded By:           Egyptian astronomers]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_marsdata():\n",
    "    url = 'https://space-facts.com/mars/'\n",
    "    marsdata_table = pd.read_html(url)\n",
    "        \n",
    "    return marsdata_table\n",
    "\n",
    "scrape_marsdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_marshemispheres():\n",
    "    browser = webdriver.Chrome('chromedriver.exe')\n",
    "    marshemis = {}\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    \n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    html = browser.page_source \n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    mylink = soup.find('img')\n",
    "    # print(soup.prettify())\n",
    "    \n",
    "    mylink.attrs\n",
    "    marshemis[\"mars_hemis\"] = mylink.attrs[\"wide-image\"]\n",
    "    #featuredimage[\"featured_image_url\"] = url2 + mylink.attrs['data-fancybox-href']\n",
    "    #soup.find(\"a\", class_=\"button fancybox\").get_link()\n",
    "    \n",
    "    return marshemispheres\n",
    "\n",
    "scrape_marshemispheres()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['title']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['title']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "url0 = 'https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced/'\n",
    "marshemis = {}\n",
    "response = requests.get(url0)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "mylink = soup.find('h2')\n",
    "\n",
    "#print(soup)\n",
    "\n",
    "type(mylink.attrs)\n",
    "mylink.attrs\n",
    "\n",
    "#marshemis[\"mars_hemis\"] = mylink.attrs[\"wide-image\"]\n",
    "\n",
    "print(mylink.attrs)\n",
    "#mylink.attrs[\"img\"]\n",
    "\n",
    "mylink.attrs['class']\n",
    "\n",
    "\n",
    "# print(soup.prettify())\n",
    "#soup.body\n",
    "#mars_weather = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "\n",
    "#type(mylink.attrs)\n",
    "# dict\n",
    "#mylink.attrs\n",
    "# {'href': 'http://example.com'}\n",
    "\n",
    "\n",
    "#featured_image_url = mylink.attrs['href']\n",
    "#data-fancybox-group = mylink.attrs['data-fancybox-group']\n",
    "#data-fancybox-href = mylink.attrs['data-fancybox-href']\n",
    "#data-link = mylink.attrs['data-link']\n",
    "\n",
    "#print(marshemis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_marsweather():\n",
    "    browser = webdriver.Chrome('chromedriver.exe')\n",
    "    marsweather = {}\n",
    "    url = 'https://twitter.com/marswxreport?lang=en'\n",
    "    \n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    html = browser.page_source \n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # print(soup.prettify())\n",
    "    \n",
    "    mylink.attrs\n",
    "    marsweather[\"mars_weather\"] = soup.find('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "    #soup.find(\"a\", class_=\"button fancybox\").get_link()\n",
    "    \n",
    "    return marsweather\n",
    "\n",
    "scrape_marsweather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1, 6):\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    quotes = soup.find_all('span', class_='text')\n",
    "\n",
    "    for quote in quotes:\n",
    "        print('page:', x, '-------------')\n",
    "        print(quote.text)\n",
    "\n",
    "    browser.click_link_by_partial_text('Next')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
